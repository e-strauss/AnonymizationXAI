{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:30.688898Z",
     "start_time": "2025-05-20T12:10:27.136470Z"
    }
   },
   "outputs": [],
   "source": [
    "from read_jsonl import read_jsonl\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Detect MPS (Apple Silicon GPU)\n",
    "force_cpu = False\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() and not force_cpu else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:30.714419Z",
     "start_time": "2025-05-20T12:10:30.709820Z"
    }
   },
   "id": "c486a426c3d223d6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = read_jsonl(\"DB-bio/combined_train_and_train_sft_anonymized.jsonl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:30.732804Z",
     "start_time": "2025-05-20T12:10:30.712132Z"
    }
   },
   "id": "dae0cc6274f108bf",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "((3876, 2), Index(['text', 'label'], dtype='object'))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:30.745955Z",
     "start_time": "2025-05-20T12:10:30.734396Z"
    }
   },
   "id": "5f1417e6dc6d1f52",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_size = 0.3\n",
    "\n",
    "# train/test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=test_size, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_texts, \"label\": val_labels})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:30.756576Z",
     "start_time": "2025-05-20T12:10:30.748965Z"
    }
   },
   "id": "fb71739ee0a729aa",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "use_distillbert = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:30.759480Z",
     "start_time": "2025-05-20T12:10:30.756942Z"
    }
   },
   "id": "f439d97832710e7d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2713 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "edf8bdaaf15b4e748bdc7077aff13929"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1163 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40a1c7b0dade48b5bc1623c02dc51d45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\") if use_distillbert else BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "\n",
    "train_dataset = train_dataset.remove_columns([\"text\"])\n",
    "val_dataset = val_dataset.remove_columns([\"text\"])\n",
    "\n",
    "train_dataset.set_format(\"torch\")\n",
    "val_dataset.set_format(\"torch\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:41.023543Z",
     "start_time": "2025-05-20T12:10:30.759862Z"
    }
   },
   "id": "fa9aaab263debc7e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model and move to MPS\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2) if use_distillbert else BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:41.838134Z",
     "start_time": "2025-05-20T12:10:41.024560Z"
    }
   },
   "id": "509af234dd43a77",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# Metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = torch.argmax(torch.tensor(logits), axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    correct = (preds == torch.tensor(labels)).sum().item()\n",
    "    total = len(labels)\n",
    "    print(f\"\\nCorrect predictions: {correct} / {total}\")\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    use_cpu= force_cpu,\n",
    "    dataloader_pin_memory=False,  # suppress pin_memory warning\n",
    "    disable_tqdm=True,\n",
    "    output_dir=\"./results/distilbert\" if use_distillbert else \"./results/bert\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=8,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=32,\n",
    "    report_to=\"none\",\n",
    "    fp16=False  # disable fp16 for MPS\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:41.841160Z",
     "start_time": "2025-05-20T12:10:41.839079Z"
    }
   },
   "id": "5e562037cd685604",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# Custom Trainer to support MPS\n",
    "class MPSTrainer(Trainer):\n",
    "    def _move_model_to_device(self, model, device):\n",
    "        print(device)\n",
    "        model.to(device)\n",
    "\n",
    "    def _prepare_inputs(self, inputs):\n",
    "        # Force inputs to MPS\n",
    "        return {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()}\n",
    "\n",
    "# Use custom Trainer\n",
    "trainer = MPSTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:10:41.856049Z",
     "start_time": "2025-05-20T12:10:41.842814Z"
    }
   },
   "id": "d979e844281e16a5",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6109, 'grad_norm': 7.521792888641357, 'learning_rate': 4.7941176470588245e-06, 'epoch': 0.047058823529411764}\n",
      "{'loss': 0.5616, 'grad_norm': 7.2485737800598145, 'learning_rate': 4.558823529411765e-06, 'epoch': 0.09411764705882353}\n",
      "{'loss': 0.4946, 'grad_norm': 7.49031400680542, 'learning_rate': 4.323529411764707e-06, 'epoch': 0.1411764705882353}\n",
      "{'loss': 0.4373, 'grad_norm': 6.766918182373047, 'learning_rate': 4.088235294117647e-06, 'epoch': 0.18823529411764706}\n",
      "\n",
      "Correct predictions: 1148 / 1163\n",
      "{'eval_loss': 0.3788065016269684, 'eval_accuracy': 0.9871023215821152, 'eval_precision': 0.9875886524822695, 'eval_recall': 0.9858407079646018, 'eval_f1': 0.9867139061116031, 'eval_runtime': 6.3705, 'eval_samples_per_second': 182.561, 'eval_steps_per_second': 2.983, 'epoch': 0.18823529411764706}\n",
      "{'loss': 0.3618, 'grad_norm': 6.805063724517822, 'learning_rate': 3.852941176470589e-06, 'epoch': 0.23529411764705882}\n",
      "{'loss': 0.3159, 'grad_norm': 6.938209533691406, 'learning_rate': 3.6176470588235296e-06, 'epoch': 0.2823529411764706}\n",
      "{'loss': 0.2846, 'grad_norm': 6.091739177703857, 'learning_rate': 3.382352941176471e-06, 'epoch': 0.32941176470588235}\n",
      "{'loss': 0.2637, 'grad_norm': 5.5982208251953125, 'learning_rate': 3.147058823529412e-06, 'epoch': 0.3764705882352941}\n",
      "\n",
      "Correct predictions: 1158 / 1163\n",
      "{'eval_loss': 0.207896426320076, 'eval_accuracy': 0.9957007738607051, 'eval_precision': 0.9929577464788732, 'eval_recall': 0.9982300884955753, 'eval_f1': 0.9955869373345102, 'eval_runtime': 6.3855, 'eval_samples_per_second': 182.132, 'eval_steps_per_second': 2.975, 'epoch': 0.3764705882352941}\n",
      "{'loss': 0.2112, 'grad_norm': 4.045458793640137, 'learning_rate': 2.9117647058823534e-06, 'epoch': 0.4235294117647059}\n",
      "{'loss': 0.2011, 'grad_norm': 4.281588077545166, 'learning_rate': 2.6764705882352945e-06, 'epoch': 0.47058823529411764}\n",
      "{'loss': 0.1644, 'grad_norm': 3.213252544403076, 'learning_rate': 2.4411764705882356e-06, 'epoch': 0.5176470588235295}\n",
      "{'loss': 0.1527, 'grad_norm': 3.1314711570739746, 'learning_rate': 2.2058823529411767e-06, 'epoch': 0.5647058823529412}\n",
      "\n",
      "Correct predictions: 1160 / 1163\n",
      "{'eval_loss': 0.12359550595283508, 'eval_accuracy': 0.9974204643164231, 'eval_precision': 0.9964664310954063, 'eval_recall': 0.9982300884955753, 'eval_f1': 0.9973474801061007, 'eval_runtime': 6.3757, 'eval_samples_per_second': 182.412, 'eval_steps_per_second': 2.98, 'epoch': 0.5647058823529412}\n",
      "{'loss': 0.1269, 'grad_norm': 2.725290060043335, 'learning_rate': 1.970588235294118e-06, 'epoch': 0.611764705882353}\n",
      "{'loss': 0.1222, 'grad_norm': 2.6048967838287354, 'learning_rate': 1.735294117647059e-06, 'epoch': 0.6588235294117647}\n",
      "{'loss': 0.1015, 'grad_norm': 1.9397982358932495, 'learning_rate': 1.5e-06, 'epoch': 0.7058823529411765}\n",
      "{'loss': 0.1028, 'grad_norm': 2.236386299133301, 'learning_rate': 1.2647058823529412e-06, 'epoch': 0.7529411764705882}\n",
      "\n",
      "Correct predictions: 1161 / 1163\n",
      "{'eval_loss': 0.08573532104492188, 'eval_accuracy': 0.998280309544282, 'eval_precision': 0.9982300884955753, 'eval_recall': 0.9982300884955753, 'eval_f1': 0.9982300884955753, 'eval_runtime': 6.3904, 'eval_samples_per_second': 181.992, 'eval_steps_per_second': 2.973, 'epoch': 0.7529411764705882}\n",
      "{'loss': 0.0936, 'grad_norm': 2.133395195007324, 'learning_rate': 1.0294117647058825e-06, 'epoch': 0.8}\n",
      "{'loss': 0.0784, 'grad_norm': 1.3161829710006714, 'learning_rate': 7.941176470588236e-07, 'epoch': 0.8470588235294118}\n",
      "{'loss': 0.0803, 'grad_norm': 1.9282656908035278, 'learning_rate': 5.588235294117648e-07, 'epoch': 0.8941176470588236}\n",
      "{'loss': 0.0782, 'grad_norm': 1.8057576417922974, 'learning_rate': 3.235294117647059e-07, 'epoch': 0.9411764705882353}\n",
      "\n",
      "Correct predictions: 1161 / 1163\n",
      "{'eval_loss': 0.0704600140452385, 'eval_accuracy': 0.998280309544282, 'eval_precision': 0.9982300884955753, 'eval_recall': 0.9982300884955753, 'eval_f1': 0.9982300884955753, 'eval_runtime': 6.3215, 'eval_samples_per_second': 183.976, 'eval_steps_per_second': 3.006, 'epoch': 0.9411764705882353}\n",
      "{'loss': 0.0795, 'grad_norm': 1.8015097379684448, 'learning_rate': 8.823529411764707e-08, 'epoch': 0.9882352941176471}\n",
      "{'train_runtime': 108.8826, 'train_samples_per_second': 24.917, 'train_steps_per_second': 1.561, 'train_loss': 0.23278589774580563, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=170, training_loss=0.23278589774580563, metrics={'train_runtime': 108.8826, 'train_samples_per_second': 24.917, 'train_steps_per_second': 1.561, 'train_loss': 0.23278589774580563, 'epoch': 1.0})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:12:30.837383Z",
     "start_time": "2025-05-20T12:10:41.942608Z"
    }
   },
   "id": "25834bed7f8ab278",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-20T12:12:30.838334Z",
     "start_time": "2025-05-20T12:12:30.835233Z"
    }
   },
   "id": "2bec0a560907fc03",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
